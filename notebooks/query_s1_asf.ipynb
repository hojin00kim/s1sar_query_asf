{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is script to query Sentinel-1 scenes through NASA ASF center\n",
    "\n",
    "input file needs to be prepared in advance in csv format and necessary information is \n",
    "* field id (or name)\n",
    "* geometry\n",
    "* the season (optional) to be processed\n",
    " \n",
    "output will be a dataframe with informatoin of scene granule that intersect the fields,\n",
    "    scene location uri at the NASA server, and satellite information\n",
    "    \n",
    "url prefix is as follows and curl is used to send string \n",
    "url https://api.daac.asf.alaska.edu/services/search/param?\n",
    "\n",
    "`curl https://api.daac.asf.alaska.edu/services/search/param? platform=Sentinel-1&beamMode=IW&processingLevel=GRD_HS,GRD_HD\n",
    "&intersectsWith=POLYGON+%28%28-94.01615528012626+42.49834642432543,-93.99159903129991+42.49834642432543,-93.99159903129991+42.52545573340149,-94.01615528012626+42.52545573340149,-94.01615528012626+42.49834642432543%29%29\n",
    "&start=2019-05-01T00:00:01UTC&end=2019-11-01T00:00:00UTC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import urllib.parse\n",
    "import asf_query as asf\n",
    "import custom_utils as cutils\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://api.daac.asf.alaska.edu/services/search/param?\"\n",
    "platform = 'Sentinel-1'\n",
    "beam_mode='IW'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  read csv file with field info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/hojin.kim/Projects/SAR-support/indigo-sar-download/data'\n",
    "\n",
    "input_csv = 'crf_sar_request_s2Tile.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, input_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tillage_date\"] = pd.to_datetime(df[\"tillage_date\"]).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initiate a sesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# define a list to store all data frame\n",
    "append_df =[]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    field_name = row['field_id']\n",
    "    base_date = row['tillage_date']\n",
    "    s2_zoneid = row['S2_Tile_ZoneID']\n",
    "    print (\"query the {}th row for field {}\".format(i, field_name))\n",
    "    geometry_wkt = row['geometry']\n",
    "    \n",
    "    # start and end data based on an event\n",
    "    start, end = cutils.image_query_day_window(base_date, 30)\n",
    "    \n",
    "    print (start, end)\n",
    "    # convert geometry to url format\n",
    "    url_geometry = asf.wkt_to_url(geometry_wkt)\n",
    "\n",
    "    # build a query for GRD\n",
    "    query = asf.build_query(start, end, platform, beam_mode, url_geometry, mapping='S1_GRD')\n",
    "    \n",
    "    # get response\n",
    "    response = session.get(query)\n",
    "\n",
    "    # output scene boudaries into a geo-dataframe for further steps\n",
    "    footprint_geodf = asf.found_list_to_df(query)\n",
    "    footprint_geodf['field_name'] = field_name\n",
    "    footprint_geodf['s2_zoneid'] = s2_zoneid\n",
    "    footprint_geodf['field_geometry'] = geometry_wkt\n",
    "\n",
    "    # append each query\n",
    "    append_df.append(footprint_geodf)\n",
    "\n",
    "\n",
    "elaspsed_time_secs = time.time() - start_time\n",
    "hours, rest = divmod(elaspsed_time_secs,3600)\n",
    "minutes, seconds = divmod(rest, 60)\n",
    "print (\"Execution took: \" , hours, \"hrs\", minutes, \"min\", seconds, \"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stack geodataframe from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gdf = pd.concat(append_df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfbase = input_csv.split('.')[0]\n",
    "stack_gdf.to_csv(os.path.join(data_dir, \n",
    "                \"{}_s1_acquistion.csv\".format(outfbase, index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop duplicate granule id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37-geo] *",
   "language": "python",
   "name": "conda-env-py37-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
